{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60561d72-75a3-4a8a-810d-356ac8ce8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Base.Iterators: partition\n",
    "using Flux\n",
    "using Flux.Optimise: update!\n",
    "using Flux: logitbinarycrossentropy\n",
    "using Images\n",
    "using MLDatasets\n",
    "using Statistics\n",
    "using Parameters: @with_kw\n",
    "using Random\n",
    "using Printf\n",
    "# using CUDAapi\n",
    "# using CuArrays\n",
    "using Zygote\n",
    "# if has_cuda()# Check if CUDA is available\n",
    "#     @info \"CUDA is on\"\n",
    "#     import CuArrays\t# If CUDA is available, import CuArrays\n",
    "#     CuArrays.allowscalar(false)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c3a8035-130b-48fb-9f6d-177226efd7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@with_kw struct HyperParams\n",
    "    batch_size::Int = 128\n",
    "    latent_dim::Int = 100\n",
    "    epochs::Int = 30\n",
    "    n_critic::Int = 3\n",
    "    clip_value::Float32 = 0.01 \n",
    "    verbose_freq::Int = 1000\n",
    "    output_x::Int = 6        # No. of sample images to concatenate along x-axis \n",
    "    output_y::Int = 6        # No. of sample images to concatenate along y-axis\n",
    "    lr_dscr::Float64 = 0.00005\n",
    "    lr_gen::Float64 = 0.00005\n",
    "end\n",
    "\n",
    "## Generator and Discriminator\n",
    "function generator(args)\n",
    "    return Chain(Dense(args.latent_dim, 6272), x->leakyrelu.(x, 0.2f0), x-> reshape(x, 7,7,128, size(x,2)),\n",
    "            ConvTranspose((4, 4), 128 => 128; stride = 2, pad = 1),\n",
    "            BatchNorm(128, leakyrelu),\n",
    "            Dropout(0.25),\n",
    "            ConvTranspose((4, 4), 128 => 64; stride = 2, pad = 1),\n",
    "            BatchNorm(64, leakyrelu),\n",
    "            Conv((7, 7), 64 => 1, tanh; stride = 1, pad = 3)) |> gpu\n",
    "end\n",
    "\n",
    "function discriminator(args)\n",
    "    return Chain(Conv((3,3), 1=>128, pad=(1,1), stride = (2,2)),\n",
    "            x->leakyrelu.(x, 0.2f0),\n",
    "            Dropout(0.4),\n",
    "            Conv((3,3), 128=>128, pad= (1,1), stride = (2,2), leakyrelu),\n",
    "            x->leakyrelu.(x, 0.2f0),\n",
    "            x -> reshape(x, :, size(x, 4)),\n",
    "            Dropout(0.25),\n",
    "            Dense(6272, 1, sigmoid)) |> gpu\n",
    "end\n",
    "\n",
    "function load_data(hparams)\n",
    "    # Load MNIST dataset\n",
    "    images, labels = MLDatasets.MNIST.traindata(Float32)\n",
    "    # Normalize to [-1, 1] and convert it to WHCN\n",
    "    image_tensor = permutedims(reshape(@.(2f0 * images - 1f0), 28, 28, 1, :), (2, 1, 3, 4))\n",
    "    # Partition into batches\n",
    "    data = [image_tensor[:,:,:,r] |> gpu for r in partition(1:60000, hparams.batch_size)]\n",
    "    return data\n",
    "end\n",
    "\n",
    "function wasserstein_loss_discr(real, fake)\n",
    "    return -mean(real) + mean(fake)\n",
    "end\n",
    "\n",
    "function wasserstein_loss_gen(out)\n",
    "    return -mean(out)\n",
    "end\n",
    "\n",
    "function train_discr(discr, original_data, fake_data, opt_discr, hparams)\n",
    "    ps = Flux.params(discr)\n",
    "    loss = 0.0\n",
    "    for i in 1:hparams.n_critic\n",
    "        loss, back = Zygote.pullback(ps) do\n",
    "                        wasserstein_loss_discr(discr(original_data), discr(fake_data))\n",
    "        end\n",
    "        grads = back(1f0)\n",
    "        update!(opt_discr, ps, grads)\n",
    "        for i in ps\n",
    "            i = clamp.(i, -hparams.clip_value, hparams.clip_value)\n",
    "        end\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\n",
    "Zygote.@nograd train_discr\n",
    "\n",
    "function train_gan(gen, discr, original_data, opt_gen, opt_discr, hparams)\n",
    "    noise = randn!(similar(original_data, (hparams.latent_dim, hparams.batch_size))) |> gpu\n",
    "    loss = Dict()\n",
    "    ps = Flux.params(gen)\n",
    "    loss[\"gen\"], back = Zygote.pullback(ps) do\n",
    "                          fake_ = gen(noise)\n",
    "                          loss[\"discr\"] = train_discr(discr, original_data, fake_, opt_discr, hparams)\n",
    "                          wasserstein_loss_gen(discr(fake_))\n",
    "    end\n",
    "    grads = back(1f0)\n",
    "    update!(opt_gen, ps, grads)\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function create_output_image(gen, fixed_noise, hparams)\n",
    "    @eval Flux.istraining() = false\n",
    "    fake_images = @. cpu(gen(fixed_noise))\n",
    "    @eval Flux.istraining() = true\n",
    "    image_array = dropdims(reduce(vcat, reduce.(hcat, partition(fake_images, hparams.output_y))); dims=(3, 4))\n",
    "    image_array = @. Gray(image_array + 1f0) / 2f0\n",
    "    return image_array\n",
    "end\n",
    "\n",
    "function train()\n",
    "    hparams = HyperParams()\n",
    "\n",
    "    data = load_data(hparams)\n",
    "\n",
    "    fixed_noise = [randn(hparams.latent_dim, 1) |> gpu for _=1:hparams.output_x*hparams.output_y]\n",
    "\n",
    "    # Discriminator\n",
    "    dscr = discriminator(hparams) \n",
    "\n",
    "    # Generator\n",
    "    gen =  generator(hparams) |> gpu\n",
    "\n",
    "    # Optimizers\n",
    "    opt_dscr = RMSProp(hparams.lr_dscr)\n",
    "    opt_gen = RMSProp(hparams.lr_gen)\n",
    "\n",
    "    isdir(\"output\")||mkdir(\"output\")\n",
    "\n",
    "    ones()\n",
    "    \n",
    "    # Training\n",
    "    train_steps = 0\n",
    "    for ep in 1:hparams.epochs\n",
    "        @info \"Epoch $ep\"\n",
    "        for x in data\n",
    "            # Update discriminator and generator\n",
    "            loss = train_gan(gen, dscr, x, opt_gen, opt_dscr, hparams)\n",
    "\n",
    "            if train_steps % hparams.verbose_freq == 0\n",
    "                @info(\"Train step $(train_steps), Discriminator loss = $(loss[\"discr\"]), Generator loss = $(loss[\"gen\"])\")\n",
    "                # Save generated fake image\n",
    "                output_image = create_output_image(gen, fixed_noise, hparams)\n",
    "                save(@sprintf(\"output/gan_steps_%06d.png\", train_steps), output_image)\n",
    "            end\n",
    "            train_steps += 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    output_image = create_output_image(gen, fixed_noise, hparams)\n",
    "    save(@sprintf(\"output/cgan_steps_%06d.png\", train_steps), output_image)\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495f1ee-0aca-4480-ba37-768920b55caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main In[10]:119\n",
      "┌ Info: Train step 0, Discriminator loss = -0.051110864, Generator loss = -0.5066731\n",
      "└ @ Main In[10]:125\n",
      "┌ Info: Precompiling PNGFiles [f57f5aa1-a3ce-4bc8-8ab9-96f992907883]\n",
      "└ @ Base loading.jl:1342\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JuliaFlux 1.6.3",
   "language": "julia",
   "name": "juliaflux-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
