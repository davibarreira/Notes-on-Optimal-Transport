\documentclass[10pt]{beamer}

% \usepackage[table,xcdraw]{xcolor}
\usepackage[square,numbers]{natbib}
\usepackage{graphicx}
\usepackage{svg}
\usepackage{pgfplots}
\usepgfplotslibrary{dateplot}

% \usetheme[progressbar=frametitle]{metropolis}
\usecolortheme{Imperial}
\usepackage{appendixnumberbeamer}

\usepackage{booktabs}
\usepackage[scale=2]{ccicons}


\usepackage{pgfplots}
\usepgfplotslibrary{dateplot}
\usepackage{xspace}
\newcommand{\themename}{\textbf{\textsc{metropolis}}\xspace}

\usepackage{amsfonts, amsmath, amsthm, amssymb}
\usepackage{bbm}
\usepackage{bm}
\usepackage{mathtools}
\usepackage[ruled,vlined]{algorithm2e}
\newlength{\commentWidth}
\setlength{\commentWidth}{7cm}
\newcommand{\atcp}[1]{\tcp*[r]{\makebox[\commentWidth]{#1\hfill}}}
\usepackage{setspace}
\usepackage[utf8]{inputenc}

\newcommand*{\QEDA}{\hfill\ensuremath{\blacksquare}}%
\newcommand*{\QEDB}{\hfill\ensuremath{\square}}%

\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage{forest}
\usetikzlibrary{trees} % this is to allow the fork right path

\setbeamertemplate{itemize items}[circle]
\setbeamertemplate{enumerate items}[default]
\usefonttheme[onlymath]{serif}


\title{\textbf{Transporte Ótimo para Redes Neurais}}
\subtitle{}
% \date{\today}
\date{}
\author{\textbf{Autor:} Davi Sales Barreira \\\hfill\\}
\institute{\includegraphics[height=0.55cm]{emaplogo.png}}
\titlegraphic{\includegraphics[height=0.35cm]{emaplogo-neg.png}}


\usepackage{caption}
\captionsetup[figure]{font=footnotesize}

\begin{document}

\maketitle

\begin{frame}{Sumário}
	\setbeamertemplate{section in toc}[sections numbered]
	\setbeamertemplate{subsection in toc}[subsections numbered]
	% \setbeamerfont{section in toc}{size=\normal}
	\setbeamerfont{subsection in toc}{size=\small}
	% \tableofcontents[hideallsubsections]
	\tableofcontents[sectionstyle=show, subsectionstyle=show]
\end{frame}

\AtBeginSection{}
\section[Introdução]{Introdução}
\begin{frame}[fragile]{Ideia Geral}

	Transporte Ótimo (OT) é uma área da matemática que estuda o problema
	de transportar ``massa'' em uma configuração para outra
	enquanto se miniza o custo de transporte.

	\vspace{3mm}
	Apesar de parecer um problema bastante específico, a ideia de se transportar objetos de maneira ótima
	é bastante ubíqua e possui diversas utilidades.

	\vspace{3mm}
	OT tem aparecido em diversas aplicações recentes de Machine Learning, como:
	\textbf{\textit{transfer learning, clustering}, redução de dimensionalidade,
		modelos generativos}, entre outros.

\end{frame}

\begin{frame}[fragile]{Ideia Geral}

	\begin{figure}[H]
		\centering
		\def\svgscale{0.7}
		\includesvg[inkscapelatex=false]{Figures/citations_distribution2}
		\caption{
			Gráficos com a evolução do número de publiações
			relacionadas a Transporte Ótimo com Machine Learning
			\citep{sales2021optimal}.}
		\label{fig:pub}
	\end{figure}

\end{frame}

\begin{frame}[fragile]{Ideia Geral}

	A solução de um problema de Transporte Ótimo sempre resulta
	em dois subprodutos, o \textbf{plano (mapa)} ótimo de transporte
	e o \textbf{custo mínimo} para realizar o transporte.

	\vspace{3mm}
	A maioria das aplicações em ML utiliza o custo mínimo para
	definir uma métrica de distância (e.g. Wasserstein). Porém,
	existem aplicações como Transfer Learning que utlilizam
	os mapas ótimos \citep{sales2021optimal}.

	\vspace{3mm}
	Nesta apresentação vamos focar na aplicação mais celebrada
	de OT em redes neurais, as chamadas
	\textbf{Wasserstein Generative Neural Networks} \citep{arjovsky2017wasserstein}.

\end{frame}

\AtBeginSection{}
\section[Teoria de Transporte Ótimo]{Teoria de Transporte Ótimo}
\subsection[Teoria OT]{Monge \& Kantorovich}
\begin{frame}[fragile]{Teoria OT - Monge \& Kantorovich}

	\textbf{Problema de Monge} -
	Qual a maneira ótima de transporta massa de uma configuração
	para outra?
	\vspace{3mm}

	\begin{figure}[H]
		\centering
		\def\svgscale{0.4}
		\includesvg[inkscapelatex=false]{Figures/mongeproblem.svg}
		\caption{Massa não pode ser separada.}
		\label{fig:mongeproblem}
	\end{figure}

	\textbf{Kantorovich Problem} -
	Relaxação do problema original de Monge.
	\vspace{3mm}

	\begin{figure}[H]
		\centering
		\def\svgscale{0.4}
		\includesvg[inkscapelatex=false]{Figures/kantorovichproblem.svg}
		\caption{Massa pode ser separada.}
		\label{fig:kantorovichproblem}
	\end{figure}

\end{frame}


\begin{frame}[fragile]{Teoria OT - Monge \& Kantorovich}

	\begin{definition}[Problema de Monge]
		Dadas duas medidas de probabilidade $\mu \in \mathcal P(X)$,
		$\nu \in \mathcal{P}(Y)$ e uma função de custo
		$c:X\times Y \to[0,+\infty]$, resolva:
		\begin{flalign}
			(MP)     &  &
			\inf
			\left\{
			\int_{X} c(x,T(x))d\mu \quad : \quad
			T_\# \mu = \nu
			\right\} &  &
		\end{flalign}

	\end{definition}

	\begin{figure}[H]
		\centering
		\def\svgscale{0.45}
		\includesvg[inkscapelatex=false]{Figures/monge_map_example.svg}
		\caption{Exemplo de dois problemas de Transporte Ótimo.}
		\label{fig:monge_map_example}
	\end{figure}

\end{frame}

\begin{frame}[fragile]{Teoria OT - Monge \& Kantorovich}

	\begin{definition}[Acoplamento (\textit{Coupling})]
		Sejam $(X,\mu)$ e $(Y,\nu)$ espaços de probabilidade. Para
		$\gamma \in \mathcal{P}(X\times Y)$, dizemos que $\gamma$
		é um acoplamento de $(\mu,\nu)$ se $(\pi_X)_\# \gamma = \mu$
		e $(\pi_Y)_\# \gamma = \nu$. Chamamos $\Pi(\mu,\nu)$
		do conjunto de \textbf{Planos de Transporte}:
		\begin{equation}
			\Pi(\mu,\nu) :=
			\left \{
			\gamma \in \mathcal{P}(X \times Y) \ :
			\ (\pi_X)_\# \gamma = \mu \quad
			\text{and} \quad
			(\pi_Y)_\# \gamma = \nu
			\right \}
		\end{equation}
	\end{definition}

	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.7\textwidth]{Figures/coupling.pdf}
		\end{center}
		\caption{Exemplos de acomplamento.}
	\end{figure}

\end{frame}

\begin{frame}[fragile]{Teoria OT - Monge \& Kantorovich}

	\begin{definition}[Problema de Kantorovich]
		Dadas duas medidas de probabilidade $\mu \in \mathcal P(X)$,
		$\nu \in \mathcal{P}(Y)$ e a função de custo
		$c:X\times Y \to[0,+\infty]$, resolva:
		\begin{flalign}
			(KP)     &  &
			\inf
			\left\{
			\int_{X \times Y} c(x,y)d\gamma \ : \
			\gamma \in \Pi(\mu,\nu)
			\right\} &  &
			\label{eq:KP2}
		\end{flalign}
		\label{def:KP}
	\end{definition}

\end{frame}

\begin{frame}[fragile]{Teoria OT - Problema Dual}

	O Problema de Kantorovich tem uma formulação dual, que
	para certas condições de regularidade possui a mesma
	solução ótima que o problema primal (dualidade forte).

	\begin{definition}[Problema Dual]
		Dadas $\mu \in \mathcal P(X)$, $\nu \in \mathcal P (Y)$ e
		custo $c:X \times Y \to \mathbb R_+$. O
		Problema Dual é
		\begin{flalign}
			\mathrm{(DP)} &  &
			\sup \left \{
			\int_X \phi \ d\mu + \int_Y \psi \ d\nu \ :
			\phi \in C_b(X) \ , \psi \in C_b(Y) \ ,
			\ \phi \oplus \psi \leq c
			\right \}
			              &  &
			\label{eqt:dualproblem}
		\end{flalign}
	\end{definition}

	Funções $\phi, \psi$ são chamdas de \textbf{Potenciais de Kantorovich}.
	Essa formulação é utilizada nas Wasserstein GANs.

\end{frame}

\subsection{Distância de Wasserstein}
\begin{frame}[fragile]{Teoria OT - Distância de Wasserstein}

	\begin{definition}[Distância de Wasserstein]

		Seja $(X,d)$ um espaço métrico polonês, com $c:X \times X \to \mathbb R$ tal que $c(x,y)=d(x,y)^p$, e
		$p \in [1,+\infty)$.
		Para $\mu,\nu \in \mathcal P_p(X)$, a distância de Wasserstein é dada por:
		\begin{equation}
			W_p(\mu,\nu) :=
			\left(
			\inf_{\gamma \in \Pi(\mu,\nu)}
			\int_{X \times X} d(x,y)^p \ d\gamma
			\right)^{1/p}
			\label{def:Wasserstein}
		\end{equation}
	\end{definition}

	$\mathcal P_p(X)$ é o espaço de medidas de probabilidade com $p$-ésimo momento.

\end{frame}

\begin{frame}[fragile]{Teoria OT - Distância de Wasserstein}

	A distância de Wasserstein preserva a geometria do espaço
	no qual está definida a medida.

	\begin{figure}[H]
		\centering
		\def\svgscale{0.45}
		\includesvg[inkscapelatex=false]{Figures/wasserstein-jsd.svg}
		\caption{Comparação entre a distância de Wasserstein e Jensen-Shannon.}
		\label{fig:pub}
	\end{figure}

\end{frame}

\begin{frame}[fragile]{Teoria OT - Distância de Wasserstein}

	Dadas duas medidas de probabilidade $\mu$ e $\nu$,
	como então computamos a distância de Wasserstein
	entre elas?

	\vspace{3mm}
	Sabemos resolver para alguns casos!
	\begin{enumerate}
		\item Distribuições em 1D (continuas e discretas);
		\item Distribuições Gaussianas em $n$ dimensões;
		\item Distribuições discretas finitas em $n$ dimensões.
	\end{enumerate}

	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.7\textwidth]{Figures/ot-1d-discrete.pdf}
		\end{center}
		\caption{Algoritmo para caso 1D com medida finita discreta.}
	\end{figure}

\end{frame}

\subsection{Variações da Distância de Wasserstein}
\begin{frame}[fragile]{Teoria OT - Variações da Distância de Wasserstein}

	Calcular a distância de Wasserstein em espaços de alta dimensão (e.g. imagens)
	é bastante custoso, pois precisamos resolver um problema de Programação Linear.

	\vspace{3mm}
	Assim, variações da distância
	de Wasserstein foram desenvolvidas. A variação mais famosa é a chamada
	distância de \textbf{Wasserstein Entrópica}.

	\begin{displaymath}
		\overline{OT}_{c,\varepsilon}(\mu,\nu):=
		\inf_{\gamma \in \Pi(\mu,\nu)} \int_{X \times Y} c(x,y) \ d\gamma + \varepsilon \text{KL}(\gamma | \mu \otimes \nu)
	\end{displaymath}

	\begin{figure}[H]
		\centering
		\def\svgscale{0.4}
		\includesvg[inkscapelatex=false]{Figures/entropic_ot.svg}
		\caption{
			Exemplo de solução de OT com regularização entrópica
			\citep{sales2021optimal}.}
		\label{fig:entropicot}
	\end{figure}

\end{frame}

\begin{frame}[fragile]{Teoria OT - Variações da Distância de Wasserstein}

	Outra variação também bastante utilizada em Machine Learning
	é a chamada \textbf{Sliced Wasserstein}.

	\begin{displaymath}
		SW_p(\mu,\nu) =
		\left(
		\int_{\mathbb S^{d-1}} [W_p(P_{\theta \#}\mu,P_{\theta \#} \nu)]^p d\theta
		\right)^\frac{1}{p}
	\end{displaymath}

	\begin{figure}[H]
		\centering
		\def\svgscale{0.12}
		\includesvg[inkscapelatex=false]{Figures/sliced-w.svg}
		\caption{
			Desenho esquemático da Sliced Wasserstein
			\citep{sales2021optimal}.}
		\label{fig:pub}
	\end{figure}

\end{frame}

\AtBeginSection{}
\section[Aplicações OT]{OT \& Redes Neurais}
\subsection[WGAN]{Introduzindo Generative Adversarial Networks}
\begin{frame}[fragile]{Introduzindo GANs}

	\textbf{Generative Adversarial Networks} (GAN)
	foram originalmente introduzidas por \citet{goodfellow2014}.
	Essas redes são utilizadas com o objetivo de gerar
	dados sintéticos realísticos a partir de dados reais.

	\begin{figure}[H]
		\centering
		\includegraphics[width=8cm]{Figures/gans-faces.png}
		\caption{Faces geradas por GANs \citep{karras2018}.}
	\end{figure}

\end{frame}

\begin{frame}[fragile]{Intrdouzindo GANs}

	A ideia geral por trás das GANs é utilizar duas redes neurais
	competindo uma com a outra, sendo uma rede responsável por
	gerar amostras parecidas com os dados reais (\textit{gerador}) , enquanto a outra
	busca identificar quando o dado é real ou sintético
	(\textit{descriminador}).

	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=1.0\textwidth]{Figures/wgan.pdf}
		\end{center}
		\caption{Generative Adversarial Network \citep{sales2021optimal}.}
	\end{figure}

\end{frame}


\begin{frame}[fragile]{Treinando GANs}

	A GAN original busca resolver o seguinte problema de otimização mini-max:
	\begin{equation*}
		\min_{G} \max_D V(D,G) =
		\mathbb{E}_{P_{data}(\bm x)}\left[\log{(D(\bm x))}\right]+
		\mathbb{E}_{P_z(\bm z)}\left[\log(1-D(G(\bm z))\right],
	\end{equation*}

	Treinamos o discriminador $D$ buscando maximizar
	a capacidade de discernir dados de $P_{data}$ de $P_g$.
	Em um segundo momento, treinamos $G$ buscando minimizar
	a distância entre $P_g$ e $P_{data}$.

	\begin{figure}[H]
		\centering
		\includegraphics[width=8cm]{Figures/gan-algorithmscheme.png}
		\caption{De (a) até (d), o desenho ilustra a evolução do
			algoritmo ao ser treinado. A linha azul representa a
			distrbuição do descriminador, a linha verde representa
			a $P_g$, e os pontos pretos representam $P_{data}$
			\citep{goodfellow2014}.}
	\end{figure}

\end{frame}

\subsection{Problemas em GANs}
\begin{frame}[fragile]{Problemas Típicos em GANs}

	GANs tradicionais possuem falhas comuns que tem sido foco
	de pesquisas.
	\small

	\begin{itemize}
		\item \textbf{Dissipação de gradientes:} Na prática, ao treinar
		      o descriminador até seu estado ótimo ($\frac{p_{data}}
			      {p_{data} + p_g}$), os gradientes tendem a se dissipar
		      no treinamento do gerador. Além disso, quando as distribuições
		      não compartilham o suporte, o gradiente se torna nulo.

		\item  \textbf{``Mode Collapse"}: Normalmente, você deseja que sua GAN
		      produza uma ampla variedade de saídas. No entanto, se um gerador produz
		      uma saída especialmente plausível, ele pode aprender a produzir apenas
		      essa saída.

		\item \textbf{Falha de Converêgncia}: GANs podem apresentar instabilidade
		      na atualização dos gradientes do gerador, levando a falhas de
		      convergência.
	\end{itemize}

\end{frame}

\subsection{Wasserstein GAN}
\begin{frame}[fragile]{Wasserstein GAN}

	\citet{arjovsky2017wasserstein} propuseram a Wasserstein GAN,
	onde se usa $W_1(P_g, P_{data})$ invés de $KL(P_g, P_{data})$ (ou variações).

	\vspace{3mm}
	Usando formulação dual da distância de Wasserstein, o problema de otimização
	da WGAN se torna:
	\begin{displaymath}
		\min_{G} W_1(P_{\text{data}},P_g) = \min_{G}
		\max_{D \in Lip_1}\mathbb E_{P_{\text{data}}}[D(x)]
		-\mathbb E_{P_{g}}[D(x)]
		\label{eq:wgan}
	\end{displaymath}

	\vspace{3mm}
	Mas como se computa o gradiente de $W_1(\cdot, \cdot)$?

\end{frame}

\begin{frame}[fragile]{Wasserstein GAN}

	\citet{arjovsky2017wasserstein} mostrou que o gradiente pode então ser calculado
	por
	\begin{displaymath}
		\nabla_{\theta_g} W_1(P_{\text{data}},P_g) = - \mathbb E_{P_{\text{data}}}[\nabla_{\theta_g} D(G(\mathbf z))].
	\end{displaymath}
	onde $\theta_g$ são os parâmetros do gerador.

	Para forçar que $D \in Lip_1$,
	os autores propuseram \textit{clippar} os parâmetros de $D$
	entre $[-a,a], a \in \mathbb R_+$.

\end{frame}

\subsection{Variações das Wasserstein GAN}
\begin{frame}[fragile]{Wasserstein GAN}

	WGANs não são perfeitas!
	\begin{enumerate}
		\item Dificuldade de treinar;
		\item Hiperparâmetro de clipping para tunar, além de tornar $D$ esparsa e instável;
	\end{enumerate}

	Várias modificações sugeridas na literatura, por exemplo:
	\begin{enumerate}
		\item \citet{gulrajani2017improved} - Trocar clipping por penalização no gradiente;
		\item \citet{genevay2018learning} - Utilizar Entropic Wasserstein;
		\item \citet{deshpande2018generative} - Utilizar Sliced-Wasserstein.
	\end{enumerate}

\end{frame}

\subsection{Outras Aplicações}
\begin{frame}[fragile]{Outras Aplicações}

	Além de GANs, Transporte Ótimo tem sido usado
	em diversas outras aplicações.

	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.8\textwidth]{Figures/categories_papers_2}
		\end{center}
		\caption{Distribuição por categoria dos 200 papers mais citados de OT com ML\citep{sales2021optimal}.}
	\end{figure}

\end{frame}

\begin{frame}[fragile]{Outras Aplicações}

	Modelo DeepJDOT de Transfer Learning em Redes Neurais \citep{damodaran2018deepjdot}.

	\vspace{3mm}
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.8\textwidth]{Figures/deepjdot.png}
		\end{center}
		\caption{Imagem de \citet{damodaran2018deepjdot}.}
	\end{figure}

\end{frame}

\begin{frame}[allowframebreaks]{References}
	\nocite{*}

	% \renewcommand{\bibsection}{\section{}}
	\renewcommand{\section}[2]{}%
	\tiny{\bibliography{ref}}
	\bibliographystyle{plainnat}
	% \bibliographystyle{plain}
	% \bibliographystyle{abbrv}
	% \bibliographystyle{apa}
\end{frame}


\end{document}
